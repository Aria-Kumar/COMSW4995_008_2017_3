{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "\n",
    "### Due: Wed Dec. 6 @ 9pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Use PCA to plot the digits dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The digits dataset is composed of a set of images of handwritten digits 0 to 9.\n",
    "There are 1797 images, each 32x32 pixels.\n",
    "If we flatten out each image we get a dataset of 1797 observations, each with 64 features, each belonging to one of 10 classes.\n",
    "We can't plot them in 64 dimensional space, so we will use PCA to reduce the dimensionality to 2.\n",
    "Hopefully the data will still be clustered by class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we'll load the data\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "X = digits['data']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using PCA from sklearn.decomposition\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a pca object that will result in 2 components being returned\n",
    "pca = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do a fit_transform on the digits data to get our new X\n",
    "# the resulting shape of the new X should be (1797,2)\n",
    "X_2d = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grab the labels from the digits dataset\n",
    "y = digits['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each label, create a scatter plot on the same figure\n",
    "# we should see that 0 and 1 are far apart, as well as 3 and 4\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "for i in range(____):\n",
    "    X_digit = X_2d[____]\n",
    "    _ = plt.scatter(X_digit[:,0],X_digit[:,1],s=80,alpha=0.8)\n",
    "_ = plt.legend(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaging we were given the image data without their targets. We can use k-means clustering to see if there are any obvious clusters in the full 64 dimensional space, and then plot the resulting cluster assignments in our 2D representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using KMeans from sklearn.cluster\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a KMeans object which will generate 10 clusters\n",
    "km = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use fit_predict() to both fit our k-means model and generate cluster predictions \n",
    "# on our full X dataset with 64 features\n",
    "# note: cluster assignment values will be from 0 to 9\n",
    "cluster_assignments = ____\n",
    "cluster_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the same plot as we did above, again using the X_2d data\n",
    "# but this time one plot per cluster\n",
    "# note that the cluster assignments should look very similar, \n",
    "#   meaning that the data is highly clustered in its original space even though it overlaps in 2d\n",
    "# also note that the colors may be different from the plot above, since there is no ordering to the clusters\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "for i in range(____):\n",
    "    cluster = X_2d[____]\n",
    "    _ = plt.scatter(cluster[:,0],cluster[:,1],s=80,alpha=0.8)\n",
    "_ = plt.legend(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing with an A/B test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we work at a large company that is developing online data science tools. Currently the tool has interface type A but we'd like to know if using interface tool B might be more efficient.\n",
    "To measure this, we'll look at length of active work on a project (aka project length).\n",
    "We'll perform an A/B test where half of the projects will use interface A and half will use interface B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in project lengths from '../data/project_lengths'\n",
    "# there should be 1000 observations for both interfaces\n",
    "df = pd.read_csv('../data/project_lengths.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the difference in mean project length between interface A and B\n",
    "# for consistency, subtracting A from B\n",
    "# hint: this number should be negative here (could interpret as faster)\n",
    "mean_A = ____\n",
    "mean_B = ____\n",
    "observed_mean_diff = mean_B - mean_A\n",
    "observed_mean_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we'll perform a permutation test to see how significant this result is\n",
    "# generate 10000 random permutation samples of mean difference\n",
    "# hint: use np.random.permutation\n",
    "perm_mean_diffs = []\n",
    "n_samples = 10000\n",
    "combined_times = np.concatenate([df.lengths_A.values, df.lengths_B.values])\n",
    "n_A = ____\n",
    "for i in range(____):\n",
    "    rand_perm = ____\n",
    "    rand_mean_A = np.mean(____)\n",
    "    rand_mean_B = np.mean(____)\n",
    "    perm_mean_diffs.append(rand_mean_B-rand_mean_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use seaborn to plot the distribution of mean differences\n",
    "# use plt.vlines to plot a line at our observed difference in means\n",
    "_ = ____\n",
    "_ = plt.vlines(observed_mean_diff,0,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the plot should seem to indicate significance, but let's calculate a one-tailed p_value\n",
    "p_value = sum(____ <= ____) / len(____)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is this significant at an alpha level of 0.05?\n",
    "# hint: it should be\n",
    "alpha_level = 0.05\n",
    "____ < ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can calculate the effect size of our observation\n",
    "observed_effect_size = np.abs(observed_mean_diff) / (np.std(combined_times))\n",
    "observed_effect_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we'll use this for the next 2 steps\n",
    "from statsmodels.stats.power import tt_ind_solve_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the power of our current experiment?\n",
    "# e.g. how likely is it that correctly decided that B is better than A \n",
    "#   given the observed effect size, number of observations and alpha level we used above\n",
    "# since these are independent samples we can use tt_ind_solve_power\n",
    "# hint: the power we get should not be good\n",
    "power = tt_ind_solve_power(effect_size = observed_effect_size,  # what we just calculated\n",
    "                           nobs1 = n_A,         # the number of observations in A\n",
    "                           alpha = alpha_level, # our alpha level\n",
    "                           power = ____,        # what we're interested in\n",
    "                           ratio = 1            # the ratio of number of observations of A and B\n",
    "                          )\n",
    "power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many observations for each of A and B would we need to get a power of .9\n",
    "#   for our observed effect size and alpha level\n",
    "# eg. having a 90% change of correctly deciding B is better than A\n",
    "n_obs_A = tt_ind_solve_power(effect_size = observed_effect_size,\n",
    "                             nobs1 = ____,\n",
    "                             alpha = alpha_level,\n",
    "                             power = ____,\n",
    "                             ratio = 1\n",
    "                            )\n",
    "n_obs_A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:coms_w4995]",
   "language": "python",
   "name": "conda-env-coms_w4995-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

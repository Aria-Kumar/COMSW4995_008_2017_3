{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "\n",
    "### Due: Wed Nov. 22 @ 9pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework we will be performing model evaluation, model selection and feature selection in both a regression and classification setting.\n",
    "\n",
    "The data we will be looking at are a subset of home sales data from King County, Washington, as we might see on a realestate website.\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Follow the comments below and fill in the blanks (____) to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try to build a model to predict adjusted sales price from a set of building features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data from file\n",
    "infile_name = '../data/house_sales_subset.csv'\n",
    "df = pd.read_csv(infile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use a subset of the columns as features\n",
    "X = df[['SqFtTotLiving','SqFtLot','Bathrooms','Bedrooms','BldgGrade']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract the target, adjusted sale price\n",
    "# Note: the '_r' here is denote the different targets for regression and classification\n",
    "y_r = df.AdjSalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into 80% train and 20% test using train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(____, ____, ____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train dummy model using DummyRegressor on the training set\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy_r = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate and print RMSE of the dummy model on the training set \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_dummy_r = dummy_r.____\n",
    "dummy_r_training_rsme = np.sqrt(mean_squared_error(____,____)\n",
    "\n",
    "print('dummy RMSE: {:.3f}'.format(dummy_r_training_rsme))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate and print R2 of the dummy model on training set\n",
    "# hint: can use models 'score' function\n",
    "# note: why is this 0?\n",
    "dummy_r_training_r2 = ____\n",
    "print('dummy r2: {:.3f}'.format(dummy_r_training_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure performance of Simple Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiate and train a simple LinearRegression model on the training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_r = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate RMSE and R2 of simple linear model on training set\n",
    "# Note the improvement over the dummy model\n",
    "lr_r_rmse = ____\n",
    "lr_r_r2 = ____\n",
    "print('simple linear RMSE: {:.3f}'.format(lr_r_rmse))\n",
    "print('simple linear r2: {:.3f}'.format(lr_r_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate mean 5-fold Cross Validation R2 score of simple linear model on the training set using cross_val_score\n",
    "# Note that in this case the difference in R2 cv score on the R2 on the full training set is small\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(LinearRegression(), ____, ____, cv=____)\n",
    "\n",
    "print('simple linear mean cv r2: {:.3f}'.format(____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a pipeline using make_pipeline to generate polynomial models\n",
    "# There should be two steps: PolynomalFeatures then LinearRegression\n",
    "# Recall: using PolynomialFeatures, we do not need to fit an intercept in the LinearRegression step\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "poly_pipeline = make_pipeline(____,____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform GridSearch over different polynomial degrees in [1,2,3,4] using the training set\n",
    "# To do this, instantiate and fit GridSearchCV on our poly_pipeline model and params set \n",
    "# hint: \"polynomialfeatures__degree\" is the parameter of interest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {____:[1,2,3,4]}\n",
    "gs = GridSearchCV(____,____).fit(____,____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print out the best score found and the best parameter setting found\n",
    "print('gs best r2 score : {:.3f}'.format(____))\n",
    "print('gs best params   : {}'.format(____))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrain poly_pipeline using the best parameter setting found above on the entire training set\n",
    "# Print the RMSE and R2 of the new model on the training set\n",
    "# hint: polynomialfeatures__degree is the parameter you need to set\n",
    "\n",
    "poly_pipeline.set_params(____).____\n",
    "\n",
    "poly_train_rmse = ____\n",
    "poly_train_r2 = ____\n",
    "\n",
    "print('polynomial training RMSE: {:.3f}'.format(poly_train_rmse))\n",
    "print('polynomial training R2  : {:.3f}'.format(poly_train_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using the newly trained model, get predictions on the full training set\n",
    "y_hat = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot predictions (x-axis) vs residuals (y-axis) of the training set\n",
    "# recall: residual = y_hat - ground_truth_y\n",
    "\n",
    "residuals = ____\n",
    "_ = plt.scatter(____,____ alpha=0.2)\n",
    "_ = plt.xlabel('y predicted')\n",
    "_ = plt.ylabel('residuals')\n",
    "# if this were a real analysis, we may want to address any of the outliers we see here\n",
    "# also you should be seeing some signs of heteroskedasticity here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate trained model on Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using our trained model, calculate R2 and RMSE on the test set\n",
    "# Note that error may have gone up slightly and r2 may have decreased slightly\n",
    "print('test RMSE: {:.3f}'.format(____))\n",
    "print('test r2  : {:.3f}'.format(____))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select the top 2 most informative features from the trained model using SelectKBest and f_regression\n",
    "# To do this, instantiate and fit SelectKbest on the training set\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "skb = SelectKBest(f_regression, ____).____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print out the selected features using skb.get_support() and the column names from X\n",
    "# hint: get_support returns a boolean mask\n",
    "kept_columns = ____\n",
    "print('kept columns: {}'.format(kept_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try to build a model to predict low vs. high adjusted sales price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create classification target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we create a binary target by thresholding at the AdjSalePriceMedian\n",
    "y_c = (df.AdjSalePrice > df.AdjSalePrice.median()).astype(int)\n",
    "\n",
    "print('proportion of low to high: {:.3f}'.format(sum(y_c)/float(len(y_c))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into 80% train and 20% test using train_test_split\n",
    "# Use our new y_c target and the same X we used for regression\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train a dummy classification model on the training set\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_c = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate Training set Accuracy of the dummy classifier\n",
    "# This should match the proportion of low to high\n",
    "dummy_c_acc = ____\n",
    "\n",
    "print('dummy accuracy: {:.3f}'.format(dummy_c_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure performance of a Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create, fit and calculate training set accuracy of a random forest with 5 trees\n",
    "# Note: why is this so high?\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = ____\n",
    "print('rf accuracy: {:.3f}'.format(____))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate mean 5-fold cross validation accuracy of a random forest with 5 trees on the training set\n",
    "# Note that it should be less than the accuracy when trained on the full training set\n",
    "scores = ____\n",
    "print('mean cv accuracy: {:.3f}'.format(____))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform cross validated grid search over the number of trees in [1,5,10] using the training set\n",
    "params = {____:[1,5,10]}\n",
    "\n",
    "gs = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print out the best score found and the best parameter setting found\n",
    "print('gs best accuracy: {:.3f}'.format(____))\n",
    "print('gs best params  : {}'.format(____))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrain on the entire training set using the best number of trees found\n",
    "rf = RandomForestClassifier(n_estimators=____).fit(X_train_c,y_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get p(y=1|x) for the entire training set\n",
    "# hint: py_pos should only contain one column\n",
    "py_pos = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot Precision (y-axis) vs. Recall (x-axis) using the targets and py_pos \n",
    "# The plot should indicate a good fit at almost any classification threshold\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(____, ____)\n",
    "\n",
    "_ = plt.step(____,____)\n",
    "_ = plt.xlabel('recall')\n",
    "_ = plt.ylabel('precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model performance on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy of the trained model on the test set\n",
    "# Note that it should not be far from the cv training set accuracy\n",
    "print('test accuracy: {:.3f}'.format(____))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select the most informative features using SelectFromModel using 'mean' as threshold using the trained model\n",
    "# note: this may select more than 2 features\n",
    "# note: we use prefit=True since the model is already trained\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "sfm = SelectFromModel(____, threshold=____, prefit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print out the selected features using sfm.get_support() and columns from X \n",
    "kept_columns = ____\n",
    "print('kept columns: {}'.format(kept_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform X_train_c into a new X containing only the selected features\n",
    "X_train_c_fs = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train a new model on the new X using the previously found best setting for n_estimators\n",
    "rf_fs = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict P(y=1|x) using the new model\n",
    "py_pos_fs = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the ROC curves of the old model and the new model on the same plot\n",
    "# Note that the full model is only a slight improvement on the model with fewer features\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr,tpr,_ = roc_curve(____, ____)\n",
    "fpr_fs,tpr_fs,_ = roc_curve(____, ____)\n",
    "\n",
    "_ = plt.step(fpr,tpr,color='blue')\n",
    "_ = plt.step(fpr_fs,tpr_fs,color='red')\n",
    "_ = plt.xlabel('fpr')\n",
    "_ = plt.ylabel('tpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Confirm that the new and old models are similar by calculating their ROC AUC values on the training set\n",
    "# hint: use the py_pos you predicted for both models\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "full_model_auc = ____\n",
    "fs_model_auc = ____\n",
    "print('full model auc: {:.3f}'.format(full_model_auc))\n",
    "print('fs model auc  : {:.3f}'.format(fs_model_auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:coms_w4995]",
   "language": "python",
   "name": "conda-env-coms_w4995-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
